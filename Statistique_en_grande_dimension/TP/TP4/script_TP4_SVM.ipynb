{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique en Grande Dimension et Apprentissage - TP 4 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les SVM à noyaux sont implémentées dans \"scikit-learn\" dans les classes \"sklearn.svm.SVC\" pour la classification et \"sklearn.svm.SVR\" pour la régression. Dans ces deux classes, on peut spécifier un noyau grâce au paramètre «kernel». Ce noyau peut être (linéaire, polynomial, RBF), mais on peut aussi définir vos propres noyaux !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 (Exemples simulés)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Echantillon(n):\n",
    "    \n",
    "    x = np.random.uniform(-3,3,n)\n",
    "    b = np.random.uniform(-3,3,n)\n",
    "    Y = np.zeros(n)\n",
    "    \n",
    "    Y[b > 0] = [1 for i in range(np.sum(b > 0))]\n",
    "    Y[b < 0] = [-1 for i in range(np.sum(b < 0))]\n",
    "    \n",
    "    return pd.DataFrame({'X1': x,'X2': x+b,'Y': Y.astype(int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "n = 200\n",
    "\n",
    "df = Echantillon(n)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#plt.plot([-3, 3], [-3, 3], sns.xkcd_rgb[\"denim blue\"], lw=3);\n",
    "\n",
    "sn = sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"Y\", palette=[\"C0\", \"C1\"], data=df, s =50)\n",
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df[\"Y\"]==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmlinear = SVC(C=100,kernel='linear')\n",
    "svmlinear.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = svmlinear.support_vectors_ # coordonnées des vecteur supports\n",
    "print(\"nombre de vecteurs supports: \", xi.shape[0],\"\\n\")\n",
    "print(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmlinear.support_) # indice des vecteur supports"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SVC intègre une spécificité intéressante, l’objet fournit automatiquement les coefficients de\n",
    "la droite de séparation lorsque le noyau est linéaire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients beta1 et beta2\n",
    "print(svmlinear.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0 = svmlinear.intercept_[0] # l'intercept beta0\n",
    "print(beta0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L'équation de l'hyperplan séparateur en fonction de x est:\n",
    "# beta1*x1 + beta2*x2 + beta0 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ici, cost = C. Il règle le taux de souplesse.\n",
    "Plus \"cost\" est grand, moins le modéle \"tolère\" les erreurs de classification. \"cost\" doit être trés grand pour avoir le SVM non flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "prediction=svmlinear.predict(df[[\"X1\",\"X2\"]])\n",
    "\n",
    "print(\"matrice de confusion\")\n",
    "M1 = confusion_matrix(df[\"Y\"], prediction)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification d'entraînement:\", M1.trace()/M1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = Echantillon(100)\n",
    "\n",
    "prediction_test = svmlinear.predict(df_test[[\"X1\",\"X2\"]])\n",
    "\n",
    "print(\"matrice de confusion\")\n",
    "M_test = confusion_matrix(df_test[\"Y\"], prediction_test)\n",
    "M_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification de test:\", M_test.trace()/M_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_defaut = SVC()\n",
    "svm_defaut # le noyau par default sur sklearn est 'rbf'\n",
    "# RBF :  Radial Basis Function, désigne souvent le noyau gaussien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_defaut.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])\n",
    "prediction_defaut=svm_defaut.predict(df_test[[\"X1\",\"X2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"matrice de confusion:\")\n",
    "M_defaut = confusion_matrix(df_test[\"Y\"], prediction_defaut)\n",
    "print(M_defaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification de test:\", M_defaut.trace()/M_defaut.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. & 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Echantillon(n,p):\n",
    "    X = np.random.randn(n*p)\n",
    "    X = X.reshape(n,p)\n",
    "    Y = np.ones(n)\n",
    "\n",
    "    df = pd.DataFrame({'X1': X[:,0],'X2': X[:,1],'Y': Y})\n",
    "\n",
    "    Norme = df[['X1','X2']].apply(lambda x: sum(x**2), axis=1)\n",
    "    Y[Norme > p] = -1\n",
    "\n",
    "    df['Y'] = Y\n",
    "    df['Y'] = df['Y'].astype(int)\n",
    "\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 2\n",
    "\n",
    "df = Echantillon(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "sn = sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"Y\", palette=[\"C0\", \"C1\"], data=df, s =50)\n",
    "sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmPoly = SVC(C=10,degree=3, gamma='auto',coef0=0.0, kernel='poly')\n",
    "svmPoly.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])\n",
    "\n",
    "svmRBF = SVC(C=10, gamma='auto', kernel='rbf')\n",
    "svmRBF.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 2\n",
    "df_test = Echantillon(n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#on crée un nouveau modèle SVM à noyau Gaussien\n",
    "svmRBF = SVC(kernel='rbf')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_RBF = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs de param_grid\n",
    "svmRBF_gscv = GridSearchCV(svmRBF, param_grid_RBF, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmRBF_gscv.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])\n",
    "\n",
    "print(\"Précision Train: \",svmRBF_gscv.score(df[[\"X1\",\"X2\"]], df[\"Y\"]))\n",
    "print(\"Précision Test: \",svmRBF_gscv.score(df_test[[\"X1\",\"X2\"]], df_test[\"Y\"]))\n",
    "print(\"\\n\")\n",
    "print(svmRBF_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les paramétres du modéle le plus performant:\n",
    "svmRBF_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "prediction_test_RBF = svmRBF_gscv.predict(df_test[[\"X1\",\"X2\"]])\n",
    "\n",
    "print(\"matrice de confusion\")\n",
    "M_smvRBF = confusion_matrix(df_test[\"Y\"], prediction_test_RBF)\n",
    "M_smvRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification de test:\", M_smvRBF.trace()/M_smvRBF.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmPOLY = SVC(kernel='poly')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_POLY = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05), \"degree\": [2,3], \"coef0\": np.arange(0,1,0.5)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmPOLY_gscv = GridSearchCV(svmPOLY, param_grid_POLY, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmPOLY_gscv.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])\n",
    "\n",
    "print(\"Précision Train: \",svmPOLY_gscv.score(df[[\"X1\",\"X2\"]], df[\"Y\"]))\n",
    "print(\"Précision Test: \",svmPOLY_gscv.score(df_test[[\"X1\",\"X2\"]], df_test[\"Y\"]))\n",
    "print(\"\\n\")\n",
    "print(svmPOLY_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les paramétres du modéle le plus performant:\n",
    "svmPOLY_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_POLY = svmPOLY_gscv.predict(df_test[[\"X1\",\"X2\"]])\n",
    "\n",
    "print(\"matrice de confusion\")\n",
    "M_smvPOLY = confusion_matrix(df_test[\"Y\"], prediction_test_POLY)\n",
    "M_smvPOLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification de test:\", M_smvPOLY.trace()/M_smvPOLY.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec un SVM linéaire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmLINEAR = SVC(kernel='linear')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_LINEAR = {\"C\": np.arange(0.1, 100)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmLINEAR_gscv = GridSearchCV(svmLINEAR, param_grid_LINEAR, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmLINEAR_gscv.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])\n",
    "\n",
    "print(\"Précision Train: \",svmLINEAR_gscv.score(df[[\"X1\",\"X2\"]], df[\"Y\"]))\n",
    "print(\"Précision Test: \",svmLINEAR_gscv.score(df_test[[\"X1\",\"X2\"]], df_test[\"Y\"]))\n",
    "print(\"\\n\")\n",
    "print(svmLINEAR_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les paramétres du modéle le plus performant:\n",
    "svmLINEAR_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_LINEAR = svmLINEAR_gscv.predict(df_test[[\"X1\",\"X2\"]])\n",
    "\n",
    "# construire la courbe ROC\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thr = metrics.roc_curve(df_test[\"Y\"], prediction_test_LINEAR)\n",
    "\n",
    "# calculer l'aire sous la courbe ROC\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# créer une figure\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "# afficher la courbe ROC\n",
    "plt.plot(fpr, tpr, '-', lw=2, label='AUC=%.2f' % auc)\n",
    "\n",
    "# donner un titre aux axes et au graphique\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('SVM Courbe ROC', fontsize=16)\n",
    "\n",
    "# afficher la légende\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "# afficher l'image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"matrice de confusion\")\n",
    "M_smvLINEAR = confusion_matrix(df_test[\"Y\"], prediction_test_LINEAR)\n",
    "M_smvLINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision de classification de test:\", M_smvLINEAR.trace()/M_smvLINEAR.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupére le meilleur modéle de 'gscv\n",
    "svmLINEAR = svmLINEAR_gscv.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmLINEAR.support_) # indice des vecteur supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de vecteurs supports: \",svmLINEAR.support_.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### En générale, un nombre important de vecteurs supports par rapport au données n'est pas bon signe.\n",
    "##### Ceci présage un modéle de mauvaise qualité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'intercept beta0\n",
    "beta0 = svmLINEAR.intercept_[0]\n",
    "print(\"beta0: \", round(beta0,3))\n",
    "\n",
    "#coefficients beta1 et beta2\n",
    "beta = svmLINEAR.coef_\n",
    "print(\"beta1: \",round(beta[0][0],3))\n",
    "print(\"beta2: \",round(beta[0][1],3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L'équation de l'hyperplan séparateur en fonction de x est:\n",
    "# beta1*x1 + beta2*x2 + beta0 = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L'équation réduite de l'hyperplan séparateur en fonction de x est:\n",
    "# x2 = a*x1 +b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -beta[0][1]/beta[0][0]\n",
    "b = -beta0/beta[0][0]\n",
    "\n",
    "print(\"a: \",round(a,3))\n",
    "print(\"b: \",round(b,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot([-2.5, 2.5], [-2.5*a+b, 2.5*a+b], sns.xkcd_rgb[\"pale red\"], lw=3);\n",
    "sn = sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"Y\", palette=[\"C0\", \"C1\"], data=df_test, s =50)\n",
    "sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N.B. Un principe usuel pour améliorer les résultats consiste à agréger les modèles, i.e. à faire une combinaison linéaire de plusieurs modèles. Ce principe pourrait être employé ici (voir Adaboost)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On doit utiliser un classifieur qui a la méthode \"predict_proba\".\n",
    "\n",
    "# https://stats.stackexchange.com/questions/27764/using-adaboost-with-svm-for-classification\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(SVC(probability=True, kernel='linear'),n_estimators=50, learning_rate=1.0, algorithm='SAMME')\n",
    "clf.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision Train: \",clf.score(df[[\"X1\",\"X2\"]], df[\"Y\"]))\n",
    "print(\"Précision Test: \",clf.score(df_test[[\"X1\",\"X2\"]], df_test[\"Y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut combiner tous les modéles et faire un vote mojoritaire pondéré:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "Estimateurs = [('poly', svmPOLY_gscv.best_estimator_),\n",
    "               ('rbf', svmRBF_gscv.best_estimator_),\n",
    "               ('linear', svmLINEAR_gscv.best_estimator_)]\n",
    "\n",
    "SVM = VotingClassifier(estimators=Estimateurs, voting='hard',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.fit(df[[\"X1\",\"X2\"]], df[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision Train: \",SVM.score(df[[\"X1\",\"X2\"]], df[\"Y\"]))\n",
    "print(\"Précision Test: \",SVM.score(df_test[[\"X1\",\"X2\"]], df_test[\"Y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 10\n",
    "\n",
    "df = Echantillon(n,p)\n",
    "df_test = Echantillon(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "Names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame({'Sepal.Length' :X[:,0],\n",
    "                     'Sepal.Width'  :X[:,1],\n",
    "                     'Petal.Length' :X[:,2],\n",
    "                     'Petal.Width'  :X[:,3],\n",
    "                     'Species'      :y})\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "print(Names)\n",
    "col = iris.columns\n",
    "sn = sns.scatterplot(x=col[2], y=col[3], hue=col[4], palette=\"viridis\", data=iris, s =50)\n",
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# on crée les données d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modéles SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. SVM Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmLINEAR = SVC(kernel='linear',probability=True)\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_LINEAR = {\"C\": np.arange(0.1, 100)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmLINEAR_gscv = GridSearchCV(svmLINEAR, param_grid_LINEAR, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmLINEAR_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Précision Train: \",round(svmLINEAR_gscv.score(X_train, y_train),3))\n",
    "print(\"Précision Test: \",round(svmLINEAR_gscv.score(X_test, y_test),3))\n",
    "print(\"\\n\")\n",
    "print(svmLINEAR_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmPOLY = SVC(kernel='poly',probability=True)\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_POLY = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05), \"degree\": [2,3,4], \"coef0\": np.arange(0,1,0.5)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmPOLY_gscv = GridSearchCV(svmPOLY, param_grid_POLY, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmPOLY_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Précision Train: \",round(svmPOLY_gscv.score(X_train, y_train),3))\n",
    "print(\"Précision Test: \",round(svmPOLY_gscv.score(X_test, y_test),3))\n",
    "print(\"\\n\")\n",
    "print(svmPOLY_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. SMV Rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#on crée un nouveau modèle SVM à noyau Gaussien\n",
    "svmRBF = SVC(kernel='rbf',probability=True)\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_RBF = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs de param_grid\n",
    "svmRBF_gscv = GridSearchCV(svmRBF, param_grid_RBF, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "svmRBF_gscv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Précision Train: \",round(svmRBF_gscv.score(X_train,y_train),3))\n",
    "print(\"Précision Test: \",round(svmRBF_gscv.score(X_test,y_test),3))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "On peut combiner tous les modéles et faire un vote mojoritaire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "Estimateurs = [('poly', svmPOLY_gscv.best_estimator_),\n",
    "               ('rbf', svmRBF_gscv.best_estimator_),\n",
    "               ('linear', svmLINEAR_gscv.best_estimator_)]\n",
    "\n",
    "poids = [1,2,2]\n",
    "\n",
    "SVM = VotingClassifier(estimators=Estimateurs, \n",
    "                       voting='soft',\n",
    "                       weights=poids,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision Train: \",round(SVM.score(X_train, y_train),3))\n",
    "print(\"Précision Test: \",round(SVM.score(X_test, y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Home = \"/home/malick/Bureau/Data/Statistique_en_grande_dimension/Donnees_knn\"\n",
    "path = \"/users/mmath/wade/Bureau/Data/Statistique_en_grande_dimension/Donnees_knn\"\n",
    "\n",
    "df_train = pd.read_csv(path_Home + \"/mnist_train.csv\",  sep=',')\n",
    "df_test = pd.read_csv(path_Home + \"/mnist_test.csv\",  sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# On sépare la variable cible des variables explicatives\n",
    "Xtrain = df_train.iloc[:,1:df_train.shape[1]]\n",
    "Ytrain = df_train.iloc[:,0:1]\n",
    "\n",
    "Xtest = df_test.iloc[:,1:df_train.shape[1]]\n",
    "Ytest = df_test.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 individus pour l'entrainement\n",
    "Xtrain_1000 = Xtrain.sample(n=500, random_state=1, replace=False)\n",
    "X_train = Xtrain_1000.reset_index(drop=True)\n",
    "\n",
    "Ytrain_1000 = Ytrain.sample(n=500, random_state=1, replace=False)\n",
    "y_train = Ytrain_1000.reset_index(drop=True)\n",
    "\n",
    "# 500 individus pour le test\n",
    "Xtest_500 = Xtest.sample(n=500, random_state=2, replace=False)\n",
    "X_test = Xtest_500.reset_index(drop=True)\n",
    "\n",
    "Ytest_500 = Ytest.sample(n=500, random_state=2, replace=False)\n",
    "y_test = Ytest_500.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modéles SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. SVM Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmLINEAR = SVC(kernel='linear')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_LINEAR = {\"C\": np.arange(0.1, 100)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmLINEAR_gscv = GridSearchCV(svmLINEAR, param_grid_LINEAR, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "t_debut = time.time()\n",
    "svmLINEAR_gscv.fit(X_train, y_train)\n",
    "t_fin = time.time()\n",
    "\n",
    "temps_SVM_Linear = (t_fin - t_debut)/60\n",
    "\n",
    "print(\"Précision Train: \",round(svmLINEAR_gscv.score(X_train, y_train),3))\n",
    "print(\"Précision Test: \",round(svmLINEAR_gscv.score(X_test, y_test),3))\n",
    "print(\"\\n\")\n",
    "print(svmLINEAR_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on crée un nouveau modèle SVM à noyau Polynomiale\n",
    "svmPOLY = SVC(kernel='poly')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_POLY = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05), \"degree\": [2,3,4], \"coef0\": np.arange(0,1,0.5)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs\n",
    "svmPOLY_gscv = GridSearchCV(svmPOLY, param_grid_POLY, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "t_debut = time.time()\n",
    "svmPOLY_gscv.fit(X_train, y_train)\n",
    "t_fin = time.time()\n",
    "\n",
    "temps_SVM_Poly = (t_fin - t_debut)/60\n",
    "\n",
    "print(\"Précision Train: \",round(svmPOLY_gscv.score(X_train, y_train),3))\n",
    "print(\"Précision Test: \",round(svmPOLY_gscv.score(X_test, y_test),3))\n",
    "print(\"\\n\")\n",
    "print(svmPOLY_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. SMV Rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#on crée un nouveau modèle SVM à noyau Gaussien\n",
    "svmRBF = SVC(kernel='rbf')\n",
    "\n",
    "#on crée un dictionnaire de toutes les valeurs que nous voulons tester\n",
    "param_grid_RBF = {\"C\": np.arange(0.1, 20), \"gamma\" : np.arange(0,1,0.05)}\n",
    "\n",
    "#on utilise gridsearch pour tester toutes les valeurs de param_grid\n",
    "svmRBF_gscv = GridSearchCV(svmRBF, param_grid_RBF, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "#ajustement du modèle aux données\n",
    "t_debut = time.time()\n",
    "svmRBF_gscv.fit(X_train,y_train)\n",
    "t_fin = time.time()\n",
    "\n",
    "temps_SVM_Rbf = (t_fin - t_debut)/60\n",
    "\n",
    "print(\"Précision Train: \",round(svmRBF_gscv.score(X_train,y_train),3))\n",
    "print(\"Précision Test: \",round(svmRBF_gscv.score(X_test,y_test),3))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(svmRBF_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_MNIST = pd.DataFrame({'SVM_Linear' :[round(svmLINEAR_gscv.score(X_test, y_test),3),temps_SVM_Linear],\n",
    "                               'SVM_Poly' :[round(svmPOLY_gscv.score(X_test, y_test),3),temps_SVM_Poly],\n",
    "                               'SVM_Rbf' :[round(svmRBF_gscv.score(X_test,y_test),3),temps_SVM_Rbf]},\n",
    "                                index = ['Précision', \"temps d'entrainement\"])\n",
    "Precision_MNIST.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
