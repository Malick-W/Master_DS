# calcul de la proba d'un lien entre deux parents et un enfant
# in : infos genetiques sur les deux parents et l'enfant (vecteurs de taille 17 : genotypes 4x4 + ploidie)
# out : proba du lien
calculerProbaLien = function(GenP1, GenP2, GenE){
# traiter seulement 2x-2x dans un premier temps (recuperer les ploidies et rentrer seulement si toutes sont egales a 2)
plo1 = GenP1[17]
plo2 = GenP2[17]
ploE = GenE[17]
if (plo1==2 & plo2==2 & ploE==2) {
p = 1
# boucler sur les 4 signaux en multipliant p par la nouvelle proba
# a chaque boucle :
# creer des vecteurs de taille 2 avec les alleles des parents et de l'enfant sur le signal
# generer les enfants virtuels du croisement, comparer avec l'enfant et deduire la proba
for (s in 1:4) {
GenP1S = GenP1[(4*(s-1)+1):(4*s)]
GenP2S = GenP2[(4*(s-1)+1):(4*s)]
GenES = GenE[(4*(s-1)+1):(4*s)]
G1 = GenP1S[1:2]
G2 = GenP2S[1:2]
GE = GenES[1:2]
EnfVirt = genererEnfVirt22(G1,G2)
nb = comparerEnf(EnfVirt, GE)
p = p*nb/4
}
}
return(p)
}
# construire pour un enfant la matrice des probas associee a tous les couples de parents potentiels
# in : numero de l'enfant
# out : matrice des probas (n lignes et n colonnes)
calculerProbasParents = function(e){
MatProbasParents = matrix(0, nrow=n, ncol=n)
# recuperer en amont la generation de l'enfant
# double boucle sur les parents
# ne rentrer que si le couple est envisageable (parents distincts de l'enfant, anterieurs, ...)
# calculer la proba du lien a l'aide des infos genetiques des parents et de l'enfant
# penser a renormaliser
for (i in 1:n) {
for (j in 1:n) {
if (i<j & i!=e[19] &  j!=e[19] & e[18]>MatIndiv[i, 18] & e[18]>MatIndiv[j, 18]) {
MatProbasParents[i,j] = calculerProbaLien(MatIndiv[i, ],MatIndiv[j, ],e)
}
}
}
s = sum(MatProbasParents)
if (s != 0){
MatProbasParents = MatProbasParents/s
}
return(MatProbasParents)
}
# pour un enfant, recherche du couple de parents le plus probable
# in : numero de l'enfant
# out : couple de parents le plus probable (vecteur de taille 4 : enfant/parent 1/parent 2/log-proba du lien)
recupParentsMax = function(e){
ParentsMax = c(e[19],0,0,0)
# calculer la matrice des probas pour tous les couples associes a l'enfant e
MatProbasParents = calculerProbasParents(e)
pmax = max(MatProbasParents)
if (pmax != 0){
IndMax = which(MatProbasParents == pmax, arr.ind = TRUE)
# si plusieurs couple de parents ont la même probabilité, on choisit aléatoirement un couple
IndMax = IndMax[sample(1:nrow(IndMax), 1),]
ParentsMax[4] = log(pmax)
ParentsMax[2] = round(IndMax[1])
ParentsMax[3] = round(IndMax[2])
}
# par convention : mettre 0-0 pour les parents si toutes les probas sont nulles, et 0 dans la case log-proba
return(ParentsMax)
}
# construire la genealogie de plus grande proba associee a la matrice des individus
# in : rien
# out : genealogie la plus probable (matrice de n lignes et 4 colonnes) munie de la log-vraisemblance
construireGen = function(){
Gen = matrix(0, nrow=n, ncol=4)
# boucler sur les individus
# chercher le couple le plus probable pour l'individu courant
# empiler le resultat
for (i in 1:n) {
Gen[i,] = recupParentsMax(MatIndiv[i, ])
}
return(list(Gen = Gen, lLik = sum(Gen[, 4])))
}
library("igraph")
GenMax = construireGen()
nodes = data.frame(id=GenMax$Gen[,1],
gen=MatIndiv[,18])
links = data.frame()
for (i in 1:n) {
if (GenMax$Gen[i,2] != 0 & GenMax$Gen[i,3] != 0){
link1 = data.frame(from=GenMax$Gen[i,2],
to=GenMax$Gen[i,1],
weight=round(exp(GenMax$Gen[i,4]),2))
link2 = data.frame(from=GenMax$Gen[i,3],
to=GenMax$Gen[i,1],
weight=round(exp(GenMax$Gen[i,4]),2))
links = rbind(links,link1,link2)
}
}
net = graph_from_data_frame(d=links, vertices=nodes, directed=TRUE)
net
library('RColorBrewer')
nombre_de_generation = max(MatIndiv[,18])
#colrs = rainbow(nombre_de_generation, alpha=.5)
colrs = brewer.pal(nombre_de_generation, "Set3")
# Attribuer des couleurs selon le type de média
V(net)$color = colrs[V(net)$gen]
V(net)$size = 12
#Fonte : 1 normal, 2 gras, 3, italique, 4 italique gras, 5 symbole
V(net)$label.font = 2
V(net)$label.color = "black"
V(net)$label.family = "Times"
# Épaisseur des liens fonction de l'intensité
E(net)$width = 1+E(net)$weight*5
# Changer la taille des flèches et la couleur des liens
E(net)$arrow.size = .05 #Taille des fléches, 1 par défaut
E(net)$arrow.width = 3 #Épaisseur des flèches, 1 par défaut
E(net)$edge.lty = 2 #Type de ligne
E(net)$label = E(net)$weight #Vecteur de type caractère utilisé pour nommer les liens
E(net)$edge.label.family = "Helvetica" #Police des labels (e.g.“Times”, “Helvetica”)
# E(net)$label.color = "black"
E(net)$edge.label.cex = 0.1 #Taille de la police pour les labels des liens
E(net)$edge.color = "gray80"
E(net)$edge.label = E(net)$weight
plot(net, main ="Représentation de la genealogie")
legend(x = "topleft", title="Génération", legend = 1:nombre_de_generation, pch=21,
text.font=4, col="#777777", pt.bg=colrs, pt.cex=2, cex=.5, bty="n", ncol=1)
# legend('topleft',legend=levels(sizeCut),pt.cex=scaled,col='black',pch=21, pt.bg='orange')
# https://f.hypotheses.org/wp-content/blogs.dir/2996/files/2017/02/visualiseR.pdf
############################################################################################
######### Données de Matiss à vérifier
# path = "/home/malick/Bureau/Master_DS/Option_Biologie/test16.csv"
# DF = read.csv(file = path)
# MatIndiv = data.matrix(DF)
# n = 16
# ncol = 4*4+3
######## commencer par creer un jeu de donnees virtuel de petite taille
# n = 6
# ncol = 4*4+3
# MatIndiv = matrix(0, nrow=n, ncol=ncol)
#
# MatIndiv[1, ] = c(10,10,0,0,40,50,0,0,40,80,0,0,110,120,0,0,2,1,1)
# MatIndiv[2, ] = c(10,20,0,0,60,60,0,0,70,80,0,0,120,130,0,0,2,1,2)
# MatIndiv[3, ] = c(20,20,0,0,50,60,0,0,80,80,0,0,110,120,0,0,2,1,3)
# MatIndiv[4, ] = c(10,20,0,0,50,60,0,0,80,80,0,0,110,120,0,0,2,2,4)
# MatIndiv[5, ] = c(10,20,0,0,60,50,0,0,70,80,0,0,130,120,0,0,2,3,5)
# MatIndiv[6, ] = c(10,20,0,0,60,40,0,0,70,40,0,0,120,120,0,0,2,3,6)
#######################################################################################
###### on simule un jeu de données plus grand
n = 30
ncol = 4*4+3
nombre_de_generation = 8
n_al = 4
MatIndiv = matrix(0, nrow=n, ncol=ncol)
for (i in 1:n) {
MatIndiv[i, ] = c(sample(1:n_al,1), sample(1:n_al,1), 0, 0,
sample(1:n_al,1), sample(1:n_al,1), 0, 0,
sample(1:n_al,1), sample(1:n_al,1), 0, 0,
sample(1:n_al,1), sample(1:n_al,1), 0, 0,
2, sample(1:nombre_de_generation,1), i)
}
##########################################################################################
# compte le nombre d'enfants virtuels de meme genotype que l'enfant de reference
# in : enfants virtuels (matrice avec un genotype sur chaque ligne), genotype de l'enfant (vecteur)
# out : le nombre d'enfants virtuels correspondant
comparerEnf = function(EnfVirt, Enf){
# attention : on pensera a trier les vecteurs avant de les comparer
EnfTri = sort(Enf)
nb = 0
for (i in 1:nrow(EnfVirt)) {
EnfVirt_Tri = sort(EnfVirt[i,])
if (sum(abs(EnfTri - EnfVirt_Tri)) == 0) {
nb = nb + 1
}
}
return(nb)
}
# genere la liste des enfants virtuels a partir du genotype des parents pour le schema 2x-2x
# in : genotype des parents (vecteurs de taille 2)
# out : liste des enfants virtuels (matrice de 4 lignes et 2 colonnes)
genererEnfVirt22 = function(GenP1s, GenP2s){
# creer les 4 enfants virtuels pour le schema 2x-2x
# x <- c(10,20)
# y <- c(30,40)
# d1 <- expand.grid(x = x, y = y)
EnfVirt = expand.grid(x = GenP1s, y = GenP2s)
return(as.matrix(EnfVirt))
}
# calcul de la proba d'un lien entre deux parents et un enfant
# in : infos genetiques sur les deux parents et l'enfant (vecteurs de taille 17 : genotypes 4x4 + ploidie)
# out : proba du lien
calculerProbaLien = function(GenP1, GenP2, GenE){
# traiter seulement 2x-2x dans un premier temps (recuperer les ploidies et rentrer seulement si toutes sont egales a 2)
plo1 = GenP1[17]
plo2 = GenP2[17]
ploE = GenE[17]
if (plo1==2 & plo2==2 & ploE==2) {
p = 1
# boucler sur les 4 signaux en multipliant p par la nouvelle proba
# a chaque boucle :
# creer des vecteurs de taille 2 avec les alleles des parents et de l'enfant sur le signal
# generer les enfants virtuels du croisement, comparer avec l'enfant et deduire la proba
for (s in 1:4) {
GenP1S = GenP1[(4*(s-1)+1):(4*s)]
GenP2S = GenP2[(4*(s-1)+1):(4*s)]
GenES = GenE[(4*(s-1)+1):(4*s)]
G1 = GenP1S[1:2]
G2 = GenP2S[1:2]
GE = GenES[1:2]
EnfVirt = genererEnfVirt22(G1,G2)
nb = comparerEnf(EnfVirt, GE)
p = p*nb/4
}
}
return(p)
}
# construire pour un enfant la matrice des probas associee a tous les couples de parents potentiels
# in : numero de l'enfant
# out : matrice des probas (n lignes et n colonnes)
calculerProbasParents = function(e){
MatProbasParents = matrix(0, nrow=n, ncol=n)
# recuperer en amont la generation de l'enfant
# double boucle sur les parents
# ne rentrer que si le couple est envisageable (parents distincts de l'enfant, anterieurs, ...)
# calculer la proba du lien a l'aide des infos genetiques des parents et de l'enfant
# penser a renormaliser
for (i in 1:n) {
for (j in 1:n) {
if (i<j & i!=e[19] &  j!=e[19] & e[18]>MatIndiv[i, 18] & e[18]>MatIndiv[j, 18]) {
MatProbasParents[i,j] = calculerProbaLien(MatIndiv[i, ],MatIndiv[j, ],e)
}
}
}
s = sum(MatProbasParents)
if (s != 0){
MatProbasParents = MatProbasParents/s
}
return(MatProbasParents)
}
# pour un enfant, recherche du couple de parents le plus probable
# in : numero de l'enfant
# out : couple de parents le plus probable (vecteur de taille 4 : enfant/parent 1/parent 2/log-proba du lien)
recupParentsMax = function(e){
ParentsMax = c(e[19],0,0,0)
# calculer la matrice des probas pour tous les couples associes a l'enfant e
MatProbasParents = calculerProbasParents(e)
pmax = max(MatProbasParents)
if (pmax != 0){
IndMax = which(MatProbasParents == pmax, arr.ind = TRUE)
# si plusieurs couple de parents ont la même probabilité, on choisit aléatoirement un couple
IndMax = IndMax[sample(1:nrow(IndMax), 1),]
ParentsMax[4] = log(pmax)
ParentsMax[2] = round(IndMax[1])
ParentsMax[3] = round(IndMax[2])
}
# par convention : mettre 0-0 pour les parents si toutes les probas sont nulles, et 0 dans la case log-proba
return(ParentsMax)
}
# construire la genealogie de plus grande proba associee a la matrice des individus
# in : rien
# out : genealogie la plus probable (matrice de n lignes et 4 colonnes) munie de la log-vraisemblance
construireGen = function(){
Gen = matrix(0, nrow=n, ncol=4)
# boucler sur les individus
# chercher le couple le plus probable pour l'individu courant
# empiler le resultat
for (i in 1:n) {
Gen[i,] = recupParentsMax(MatIndiv[i, ])
}
return(list(Gen = Gen, lLik = sum(Gen[, 4])))
}
library("igraph")
GenMax = construireGen()
nodes = data.frame(id=GenMax$Gen[,1],
gen=MatIndiv[,18])
links = data.frame()
for (i in 1:n) {
if (GenMax$Gen[i,2] != 0 & GenMax$Gen[i,3] != 0){
link1 = data.frame(from=GenMax$Gen[i,2],
to=GenMax$Gen[i,1],
weight=round(exp(GenMax$Gen[i,4]),2))
link2 = data.frame(from=GenMax$Gen[i,3],
to=GenMax$Gen[i,1],
weight=round(exp(GenMax$Gen[i,4]),2))
links = rbind(links,link1,link2)
}
}
net = graph_from_data_frame(d=links, vertices=nodes, directed=TRUE)
net
library('RColorBrewer')
nombre_de_generation = max(MatIndiv[,18])
#colrs = rainbow(nombre_de_generation, alpha=.5)
colrs = brewer.pal(nombre_de_generation, "Set3")
# Attribuer des couleurs selon le type de média
V(net)$color = colrs[V(net)$gen]
V(net)$size = 12
#Fonte : 1 normal, 2 gras, 3, italique, 4 italique gras, 5 symbole
V(net)$label.font = 2
V(net)$label.color = "black"
V(net)$label.family = "Times"
# Épaisseur des liens fonction de l'intensité
E(net)$width = 1+E(net)$weight*5
# Changer la taille des flèches et la couleur des liens
E(net)$arrow.size = .05 #Taille des fléches, 1 par défaut
E(net)$arrow.width = 3 #Épaisseur des flèches, 1 par défaut
E(net)$edge.lty = 2 #Type de ligne
E(net)$label = E(net)$weight #Vecteur de type caractère utilisé pour nommer les liens
E(net)$edge.label.family = "Helvetica" #Police des labels (e.g.“Times”, “Helvetica”)
# E(net)$label.color = "black"
E(net)$edge.label.cex = 0.1 #Taille de la police pour les labels des liens
E(net)$edge.color = "gray80"
E(net)$edge.label = E(net)$weight
plot(net, main ="Représentation de la genealogie")
legend(x = "topleft", title="Génération", legend = 1:nombre_de_generation, pch=21,
text.font=4, col="#777777", pt.bg=colrs, pt.cex=2, cex=.5, bty="n", ncol=1)
# legend('topleft',legend=levels(sizeCut),pt.cex=scaled,col='black',pch=21, pt.bg='orange')
# https://f.hypotheses.org/wp-content/blogs.dir/2996/files/2017/02/visualiseR.pdf
############################################################################################
setwd("~/Bureau/Master_DS/Statistique_en_grande_dimension/TP/TP2")
library(glmnet)
install.packages("glmnet")
library(glmnet)
## EXERCICE 1
p=200
n=100
sigma=0.5
s=10
theta=c(rep(1,s/2),rep(-1,s/2),rep(0,p-s))
x=matrix(rnorm(n*p),n,p)
simuy=function(n,p,theta,sigma,x){
epsilon=(sigma*rnorm(n))
y=x%*%theta+sigma*epsilon
return(y)
}
y=simuy(n,p,theta,sigma,x)
## Q2
LASSO_ex1=glmnet(x,y)
plot(y)
line(y)
lines(y)
LASSO_ex1
plot(LASSO_ex1)
dev.off()
plot(LASSO_ex1)
##Q5
v=coef(LASSO_ex1,s=0.12080)
v[1:30]
##Q6 : fonction predict
Ytest=x%*%theta+rnorm(n)
Ypred=predict(LASSO_ex1,x, s=0.3)
ErreurPred=sqrt(sum((Ypred-Ytest)^2))
ErreurPred/sqrt(n)
ValSetX=matrix(rnorm(n*p),nr=n)
Ytest=ValSetX%*%theta+sigma*rnorm(n)
Ypred=predict(LASSO_ex1, ValSetX, s=0.3)
ErreurPredCar=(sum((Ypred-Ytest)^2))
ErreurPredCar/n
##Q7 : Validation Croisée
cvLASSO_ex1=cv.glmnet(x,y)
png(file = "fig1_valid_croisee_LASSO_ex1.png", width = 800, height = 700)
plot(cvLASSO_ex1)
plot(cvLASSO_ex1)
dev.off()
bestLambda = cvLASSO_ex1$lambda.min
## Q8c : Test de la fonction predict avec cette valeur de lambda
Ypred=predict(LASSO_ex1, ValSetX, s=bestLambda)
MSE=(sum((Ypred-Ytest)^2))
MSE/n
Rdeux=1-(sum(Ytest-Ypred)^2)/sum(Ytest^2)
##Q8cbis : on reprédit avec le modèle classique où l'on a conservé que
## les variables sélectionnées par le LASSO
thetaselect=coef(cvLASSO_ex1,s=bestLambda)
support=which(thetaselect!=0)
selectlm=lm(y~x[,support])
thetachap=coef(selectlm)
Ypredlm=thetachap[1]+ValSetX[,support]%*%thetachap[-1]
MSElm=(sum(Ytest-Ypredlm)^2)
Rdeuxlm=1-(sum(Ytest-Ypredlm)^2)/sum(Ytest^2)
## Q10 : avec le Ridge
Ridge_ex1=glmnet(x,y,alpha=0)
png(file = "fig1_regularisation_Ridge_ex1.png", width = 800, height = 700)
plot(Ridge_ex1)
dev.off()
cvRidge_ex1=cv.glmnet(x,y)
png(file = "fig1_valid_croisee_Ridge_ex1.png", width = 800, height = 700)
plot(cvRidge_ex1)
dev.off()
bestLambda = cvRidge_ex1$lambda.min
## Chargement de la base
leukemia_small= read.csv("leukemia_small.csv")
#  gènes = matrice X et Y réponse
X = as.matrix(t(leukemia_small))
Y = c(rep(1,20),rep(0,14),rep(1,27),rep(0,11))
#  n = 72 patients et p = 3571 genes
colnames(X)=1:ncol(X)
rownames(X) = 1:nrow(X)
n = nrow(X)
p = ncol(X)
# Frequencies de 0/1 dans les observations
mean(Y == 0)
mean(Y == 1)
# Densité empirique des variables explicatives
hist(as.vector(X), breaks=sqrt(n*p), probability = TRUE, main = "Histogram of the genes log-expression", xlab="Genes log-expression")
# Moyenne sur chaque gene
MGenes = apply(X, 2, mean)
# Q-Q plot des covariables conditionnelles (seulement sur les premiers genes)
# Conditionnellement Gaussiennes ? Pas clair
qqnorm(X[Y == 0, 2])
qqline(X[Y == 0, 2])
qqnorm(X[Y == 1, 1])
qqline(X[Y == 1, 1])
# PCA sur X
PCALeuk = prcomp(X, center = TRUE, scale = TRUE)
summary(PCALeuk)
# On retient les Axes 1-2-3 et on représente graphiquements les plans correspondants
par(mfrow=c(1,3))
# Axes 1-2
plot(PCALeuk$x[, 1], PCALeuk$x[, 2], pch = 19, xlab = "Pr Comp 1", ylab = "Pr Comp 2", col = 2+Y)
text(PCALeuk$x[, 1], PCALeuk$x[, 2], labels=rownames(PCALeuk$x), cex=0.7, pos = 3, col = 2+Y)
# Axes 1-3
plot(PCALeuk$x[, 1], PCALeuk$x[, 3], pch = 19, xlab = "Pr Comp 1", ylab = "Pr Comp 3", col = 2+Y)
text(PCALeuk$x[, 1], PCALeuk$x[, 3], labels=rownames(PCALeuk$x), cex=0.7, pos = 3, col = 2+Y)
# Axes 2-3
plot(PCALeuk$x[, 2], PCALeuk$x[, 3], pch = 19, xlab = "Pr Comp 2", ylab = "Pr Comp 3", col = 2+Y)
text(PCALeuk$x[, 2], PCALeuk$x[, 3], labels=rownames(PCALeuk$x), cex=0.7, pos = 3, col = 2+Y)
# approche standard non consistante car p>> n
classic_glm=glm(Y ~ X[,1:73]-1, family = binomial(link = "logit")) # X-1 means 'X with no intercept'
classic_glm
## A partir de maintenant, Régression pénalisée
## On coupe l'échantillon en deux :2/3 (Apprentissage) 1/3 (Validation)
IndTrain = sample(1:n)[1:(2*n/3)] ## Découpage aléatoire
TrainSetX = X[IndTrain,]
TrainSetY = Y[IndTrain]
IndVal = setdiff(1:n, IndTrain)
ValSetX = X[IndVal,]
ValSetY = Y[IndVal]
# Apprentissage via regression logistique en mode Lasso, Ridge, Elastic-Net
TrainLasso <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=1)
TrainRidge <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=0)
TrainEN1 <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=0.1)
TrainEN2 <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=0.25)
TrainEN3 <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=0.5)
TrainEN4 <- glmnet(TrainSetX, TrainSetY, family="binomial", alpha=0.75)
# Affichage chemins de régularisation
dev.off()
png(file = "chemins_regula_leukemia.png", width = 800, height = 700)
par(mfrow=c(3,2))
plot(TrainLasso)
plot(TrainRidge)
plot(TrainEN1)
plot(TrainEN2)
plot(TrainEN3)
plot(TrainEN4)
dev.off()
## Extraction d'un coefficient
v=coef(TrainLasso,s=0.043300)
which(v!=0)
v[which(v!=0)]
## Validation croisée pour le choix optimal du Lambda
LambdaLasso = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=1)
LambdaRidge = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=0)
LambdaEN1 = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=0.1)
LambdaEN2 = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=0.25)
LambdaEN3 = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=0.5)
LambdaEN4 = cv.glmnet(TrainSetX, TrainSetY, family="binomial", type.measure="class", alpha=0.75)
# best lambda
bestLambdaLasso = LambdaLasso$lambda.min
bestLambdaRidge = LambdaRidge$lambda.min
bestLambdaEN1 = LambdaEN1$lambda.min
bestLambdaEN2 = LambdaEN2$lambda.min
bestLambdaEN3 = LambdaEN3$lambda.min
bestLambdaEN4 = LambdaEN4$lambda.min
# Naturellement, lambda(Ridge) >> lambda(Lasso) et lambda(Elastic-Net)
# Evolution de l'erreur de classification avec log(lambda)
png(file = "validation_croisee_leukemia.png", width = 800, height = 700)
par(mfrow=c(3,2))
plot(LambdaLasso)
plot(LambdaRidge)
plot(LambdaEN1)
plot(LambdaEN2)
plot(LambdaEN3)
plot(LambdaEN4)
dev.off()
# Prédiction sur la partie de l'échantillon laissée de côté
ValSetYPredLasso = as.numeric(predict(LambdaLasso$glmnet.fit, ValSetX, s=bestLambdaLasso, type="class"))
ValSetYPredRidge = as.numeric(predict(LambdaRidge$glmnet.fit, ValSetX, s=bestLambdaRidge, type="class"))
ValSetYPredEN1 = as.numeric(predict(LambdaEN1$glmnet.fit, ValSetX, s=bestLambdaEN1, type="class"))
ValSetYPredEN2 = as.numeric(predict(LambdaEN2$glmnet.fit, ValSetX, s=bestLambdaEN2, type="class"))
ValSetYPredEN3 = as.numeric(predict(LambdaEN3$glmnet.fit, ValSetX, s=bestLambdaEN3, type="class"))
ValSetYPredEN4 = as.numeric(predict(LambdaEN4$glmnet.fit, ValSetX, s=bestLambdaEN4, type="class"))
# Erreur de classification
sum(abs(ValSetY - ValSetYPredLasso))/24
sum(abs(ValSetY - ValSetYPredRidge))/24
sum(abs(ValSetY - ValSetYPredEN1))/24
sum(abs(ValSetY - ValSetYPredEN2))/24
sum(abs(ValSetY - ValSetYPredEN4))/24
# Genes sélectionnés
SelLasso = predict(LambdaLasso$glmnet.fit, TrainSetX, s=bestLambdaLasso, type="nonzero")
SelRidge = predict(LambdaRidge$glmnet.fit, TrainSetX, s=bestLambdaRidge, type="nonzero")
SelEN1 = predict(LambdaEN1$glmnet.fit, TrainSetX, s=bestLambdaEN1, type="nonzero")
SelEN2 = predict(LambdaEN2$glmnet.fit, TrainSetX, s=bestLambdaEN2, type="nonzero")
SelEN3 = predict(LambdaEN3$glmnet.fit, TrainSetX, s=bestLambdaEN3, type="nonzero")
SelEN4 = predict(LambdaEN4$glmnet.fit, TrainSetX, s=bestLambdaEN4, type="nonzero")
## Pour faire mieux, chercher d'autres techniques
## Pour faire mieux, chercher d'autres techniques
## Sparse PCA/Groupe Lasso/Sparse Clustering....
## Pour faire mieux, chercher d'autres techniques
## Sparse PCA/Groupe Lasso/Sparse Clustering....
## Pour faire mieux, chercher d'autres techniques
## Sparse PCA/Groupe Lasso/Sparse Clustering....
## Pour faire mieux, chercher d'autres techniques
## Sparse PCA/Groupe Lasso/Sparse Clustering....
